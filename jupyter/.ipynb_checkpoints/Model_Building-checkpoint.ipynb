{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52069b96-0bf5-482f-99b8-4cabfb651674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "841a609b-87de-4d47-a44c-34319ecc1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error,mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a3fd3-e81c-4aea-b87a-22961a8fd0a6",
   "metadata": {},
   "source": [
    "# **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a88a7d6-0a34-4bdd-af6d-aa0cecf2e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_collection import LinearRegression, RidgeRegression, XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30c61910-41f1-4397-90ba-ceaffe59f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9bb7e65-efcb-4f7d-b5a5-3f4efb3c4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Price\"])\n",
    "y = data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea225393-dbf3-4636-9906-bb0d3b967f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e15427b7-ff98-47d7-9e57-ae00d877d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af625548-e859-48c3-a77b-1e0f41bd78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d4d325-fa9a-4e19-a34e-d4cb53cc4cff",
   "metadata": {},
   "source": [
    "## **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f05f54f-dcdd-4601-93db-a05c8f5c938e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "681c83de-761c-41fe-a527-ec4fd0d78a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e750a5af-d690-43ed-b5ef-dd64cbd9d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(y_test_log, y_pred_lr)\n",
    "mae = mean_absolute_error(y_test_log, y_pred_lr)\n",
    "r2 = r2_score(y_test_log, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e47c94b-2e65-43da-bb2c-e3ad12d8390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Linear Regression\"] = [rmse, mae, r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b50717a-fa40-42d0-b22f-4af76de0356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression — RMSE: 1.273, MAE: 0.748, R²: 0.421\n"
     ]
    }
   ],
   "source": [
    "print(f\"Linear Regression — RMSE: {rmse:.3f}, MAE: {mae:.3f}, R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999f2a1-4ff2-489e-97a4-73314e2af871",
   "metadata": {},
   "source": [
    "## **Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45b4f288-8946-42ad-9120-fcbbf88d1adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeRegression(alpha=1.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = RidgeRegression(alpha=1.0)  \n",
    "ridge.fit(X_train_scaled, y_train_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "95cd0f29-2d2d-4071-8eaf-fd64b6da495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ridge = ridge.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4cb9043-1b57-4262-95e2-722b13972c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ridge = root_mean_squared_error(y_test_log, y_pred_ridge)\n",
    "mae_ridge = mean_absolute_error(y_test_log, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test_log, y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df68bac7-3aad-4b88-8667-2b750b7c9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"Ridge Regression\"] = [rmse_ridge, mae_ridge, r2_ridge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71ca8b0c-1d29-4b4f-8077-b94c0053ed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression — RMSE: 1.272, MAE: 0.751, R²: 0.422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ridge Regression — RMSE: {rmse_ridge:.3f}, MAE: {mae_ridge:.3f}, R²: {r2_ridge:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea169a-5a50-41a4-b40b-66cb5e44cd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58d04f83-5b72-4a08-b754-f72c54e686c2",
   "metadata": {},
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caf6b4e7-360c-4dad-8e97-29d356045723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError:\n",
    "    def loss(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "    def gradient(self, y_true, y_pred):\n",
    "        return 2 * (y_pred - y_true)\n",
    "\n",
    "    def hessian(self, y_true, y_pred):\n",
    "        return np.full_like(y_true, 2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9329935-93cf-4136-a68a-c3b0f2f7323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"gamma\": 0.0,\n",
    "    \"min_child_weight\": 1.0,\n",
    "    \"colsample_bynode\": 1.0,\n",
    "    \"base_score\": 0.5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54d4f42a-26d5-4e86-bd3e-76f216dcc2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:166: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  child = self.left if row[self.split_feature_idx] <= self.threshold else self.right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] train loss = 1849418601045118.2\n",
      "[1] train loss = 1541324430690183.8\n",
      "[2] train loss = 1293849179045754.0\n",
      "[3] train loss = 1090870865458471.9\n",
      "[4] train loss = 928041661873180.4\n",
      "[5] train loss = 795055826344439.1\n",
      "[6] train loss = 684839239336238.0\n",
      "[7] train loss = 593887986867274.0\n",
      "[8] train loss = 519589397929973.4\n",
      "[9] train loss = 459952682652591.94\n",
      "[10] train loss = 409923397689845.2\n",
      "[11] train loss = 368137671009084.94\n",
      "[12] train loss = 334961595709049.2\n",
      "[13] train loss = 308052102690052.3\n",
      "[14] train loss = 284829259885125.56\n",
      "[15] train loss = 263133573931749.53\n",
      "[16] train loss = 247341143549512.94\n",
      "[17] train loss = 233439817195526.22\n",
      "[18] train loss = 222551745424720.94\n",
      "[19] train loss = 212145528524863.22\n",
      "[20] train loss = 204932270163526.4\n",
      "[21] train loss = 198220346491703.44\n",
      "[22] train loss = 192430961847823.47\n",
      "[23] train loss = 187226745150254.97\n",
      "[24] train loss = 182735087027094.44\n",
      "[25] train loss = 178309803539712.2\n",
      "[26] train loss = 174491648560483.16\n",
      "[27] train loss = 171561605526070.5\n",
      "[28] train loss = 168576996898118.5\n",
      "[29] train loss = 165246820900206.53\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = XGBoostRegressor(params=params, random_seed=42)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, objective=MeanSquaredError(), num_boost_round=30, verbose=True)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c179da0a-c110-4f92-a515-526b58be1134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12997664.760, MAE: 6340463.189, R²: 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse_xg = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae_xg = mean_absolute_error(y_test, y_pred)\n",
    "r2_xg = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse_xg:.3f}, MAE: {mae_xg:.3f}, R²: {r2_xg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8c0ce-d7ff-4959-810d-edad93c7a190",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01ccfbca-ec77-4131-b150-8b83b0b14eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.15],  \n",
    "    'max_depth': [4, 5],            \n",
    "    'reg_lambda': [1.0, 1.5],       \n",
    "    'min_child_weight': [2, 3],     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1738a2ec-cc8b-435d-966f-0bd2d8d931f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all combinations of parameters\n",
    "grid = list(product(\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['max_depth'],\n",
    "    param_grid['reg_lambda'],\n",
    "    param_grid['min_child_weight']\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8a967726-a427-4a36-a0f7-671903b805d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df18e286-c290-4d01-bd32-1a1bae35c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:166: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  child = self.left if row[self.split_feature_idx] <= self.threshold else self.right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.05, depth=4, lambda=1.0, child=2 => R² = 0.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:166: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  child = self.left if row[self.split_feature_idx] <= self.threshold else self.right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.05, depth=4, lambda=1.0, child=3 => R² = 0.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:166: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  child = self.left if row[self.split_feature_idx] <= self.threshold else self.right\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.05, depth=4, lambda=1.5, child=2 => R² = 0.4486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:166: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  child = self.left if row[self.split_feature_idx] <= self.threshold else self.right\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 18\u001b[0m\n\u001b[0;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: lr,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: depth,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_score\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m  XGBoostRegressor(params, random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_split, y_train_split, objective\u001b[38;5;241m=\u001b[39mMeanSquaredError(), num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     19\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_split)\n\u001b[0;32m     21\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_val_split, y_val_pred)\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:74\u001b[0m, in \u001b[0;36mXGBoostRegressor.fit\u001b[1;34m(self, X, y, objective, num_boost_round, verbose)\u001b[0m\n\u001b[0;32m     71\u001b[0m hessians \u001b[38;5;241m=\u001b[39m objective\u001b[38;5;241m.\u001b[39mhessian(y, current_predictions)\n\u001b[0;32m     72\u001b[0m sample_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsample \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(y), size\u001b[38;5;241m=\u001b[39mmath\u001b[38;5;241m.\u001b[39mfloor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsample\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 74\u001b[0m booster \u001b[38;5;241m=\u001b[39m TreeBooster(X, gradients, hessians, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, sample_idxs, feature_importance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importance_)\n\u001b[0;32m     75\u001b[0m current_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m booster\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboosters\u001b[38;5;241m.\u001b[39mappend(booster)\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:106\u001b[0m, in \u001b[0;36mTreeBooster.__init__\u001b[1;34m(self, X, g, h, params, max_depth, idxs, feature_importance)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_so_far \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_insert_child_nodes()\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:120\u001b[0m, in \u001b[0;36mTreeBooster._maybe_insert_child_nodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m right_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m TreeBooster(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs[left_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importance)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m TreeBooster(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs[right_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importance)\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:106\u001b[0m, in \u001b[0;36mTreeBooster.__init__\u001b[1;34m(self, X, g, h, params, max_depth, idxs, feature_importance)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_so_far \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_insert_child_nodes()\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:120\u001b[0m, in \u001b[0;36mTreeBooster._maybe_insert_child_nodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m right_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m TreeBooster(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs[left_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importance)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m TreeBooster(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs[right_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_importance)\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:106\u001b[0m, in \u001b[0;36mTreeBooster.__init__\u001b[1;34m(self, X, g, h, params, max_depth, idxs, feature_importance)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score_so_far \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_insert_child_nodes()\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:110\u001b[0m, in \u001b[0;36mTreeBooster._maybe_insert_child_nodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_insert_child_nodes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc):\n\u001b[1;32m--> 110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_better_split(i)\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Jupyter Folder\\7th SEM Final Proj\\jupyter\\model_collection.py:127\u001b[0m, in \u001b[0;36mTreeBooster._find_better_split\u001b[1;34m(self, feature_idx)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_better_split\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_idx):\n\u001b[1;32m--> 127\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs, feature_idx]\n\u001b[0;32m    128\u001b[0m     g, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midxs]\n\u001b[0;32m    130\u001b[0m     sort_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(x)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:12664\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12590\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12592\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12593\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12594\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12662\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mas_array()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interleave(dtype\u001b[38;5;241m=\u001b[39mdtype, na_value\u001b[38;5;241m=\u001b[39mna_value)\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1754\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m   1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m-> 1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome items were not contained in blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_r2 = float('-inf')\n",
    "best_params = None\n",
    "best_feature_importance = None\n",
    "\n",
    "for lr, depth, reg, child_weight in grid:\n",
    "    params = {\n",
    "        'learning_rate': lr,\n",
    "        'max_depth': depth,\n",
    "        'reg_lambda': reg,\n",
    "        'min_child_weight': child_weight,\n",
    "        'colsample_bynode': 1.0,\n",
    "        'gamma': 0.0,\n",
    "        'subsample': 1.0,\n",
    "        'base_score': 0.5\n",
    "    }\n",
    "\n",
    "    model =  XGBoostRegressor(params, random_seed=42)\n",
    "    model.fit(X_train_split, y_train_split, objective=MeanSquaredError(), num_boost_round=50)\n",
    "    y_val_pred = model.predict(X_val_split)\n",
    "\n",
    "    r2 = r2_score(y_val_split, y_val_pred)\n",
    "    print(f\"lr={lr}, depth={depth}, lambda={reg}, child={child_weight} => R² = {r2:.4f}\")\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params = params.copy()\n",
    "        best_feature_importance = model.feature_importance_.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8f581-ca28-43d1-ac9c-29133e14a657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a4691-e109-4a1d-a791-eeb1d62f1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model on full training set\n",
    "final_model = XGBoostRegressor(params=best_params, random_seed=42)\n",
    "final_model.fit(X_train, y_train, objective=MeanSquaredError(), num_boost_round=50)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred)\n",
    "r2_xgb = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nFinal Test Results:\")\n",
    "print(f\"Best Params: {best_params}\")\n",
    "print(f\"RMSE: {rmse_xgb:.3f}, MAE: {mae_xgb:.3f}, R²: {r2_xgb:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6b9a9-df78-4a03-84ec-279a4caffbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"XGBoost (Tuned):\"] = [rmse_xgb, mae_xgb, r2_xgb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13edca42-3516-43b8-afbf-d9bcac0a1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results, index=[\"RMSE\", \"MAE\", \"R²\"]).T.round(3)\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d2bc3-f57a-4b0b-a009-41f280471949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure feature names are known\n",
    "feature_names = X_train.columns  # Adjust if needed\n",
    "\n",
    "# Convert importance dict (index-based) to feature name mapping\n",
    "importance_named = {\n",
    "    feature_names[k]: v for k, v in best_feature_importance.items()\n",
    "}\n",
    "\n",
    "# Sort by importance (highest first)\n",
    "sorted_importance = sorted(importance_named.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Print\n",
    "print(\"\\nTop Features by Importance (Total Gain):\")\n",
    "for i, (feature, score) in enumerate(sorted_importance, 1):\n",
    "    print(f\"{i}. {feature:<25} : {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88215879-ebd8-4f5a-bb74-04d7d542b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def permutation_importance(model, X, y, metric=mean_squared_error, n_repeats=5):\n",
    "    baseline_preds = model.predict(X)\n",
    "    baseline_score = metric(y, baseline_preds)\n",
    "\n",
    "    importances = {}\n",
    "    for col in X.columns:\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_shuffled = X.copy()\n",
    "            X_shuffled[col] = np.random.permutation(X_shuffled[col])\n",
    "            preds = model.predict(X_shuffled)\n",
    "            score = metric(y, preds)\n",
    "            scores.append(score - baseline_score)\n",
    "        importances[col] = np.mean(scores)\n",
    "    \n",
    "    return pd.Series(importances).sort_values(ascending=False)\n",
    "\n",
    "# Example\n",
    "importances = permutation_importance(final_model, X_test, y_test_log)\n",
    "print(importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89082388-7255-48c1-9e2c-b0a43005c561",
   "metadata": {},
   "source": [
    "# **Saving Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8fa5af-5349-4f63-a96b-70b61b891314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Bundle everything into a dictionary\n",
    "# model_package = {\n",
    "#     \"model\": final_model,\n",
    "#     \"best_params\": best_params,\n",
    "#     \"feature_importance\": best_feature_importance\n",
    "# }\n",
    "\n",
    "# # Save to file with your desired name\n",
    "# with open(\"house_price.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(model_package, f)\n",
    "\n",
    "# print(\"Model, parameters, and feature importance saved as house_price.pkl.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e4139-7b51-4f6b-967a-6581154bb85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d7420-748d-4c24-a4ef-d88a2269a83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
